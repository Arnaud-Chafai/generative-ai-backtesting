# ğŸ¯ Parameter Optimizer - GuÃ­a Completa

## Â¿QuÃ© es el Parameter Optimizer?

El **Parameter Optimizer** es una herramienta que busca automÃ¡ticamente la mejor combinaciÃ³n de parÃ¡metros para tu estrategia de trading usando **Grid Search**.

En lugar de probar parÃ¡metros manualmente, el optimizador:
1. âœ… Define rangos de valores a probar
2. âœ… Genera todas las combinaciones posibles
3. âœ… Ejecuta un backtest para cada combinaciÃ³n
4. âœ… Retorna la mejor segÃºn la mÃ©trica elegida

---

## ğŸš€ Inicio RÃ¡pido (5 minutos)

```python
import pandas as pd
from optimization.optimizer import ParameterOptimizer
from strategies.examples.breakout_simple import BreakoutSimple
from utils.timeframe import Timeframe

# 1. Cargar datos (UNA VEZ)
df = pd.read_csv('data/laboratory_data/BTC/Timeframe.M5.csv',
                  index_col='Time', parse_dates=['Time'])

# 2. Crear optimizador
optimizer = ParameterOptimizer(
    strategy_class=BreakoutSimple,
    market_data=df,  # âœ… Inyectar datos
    symbol='BTC',
    timeframe=Timeframe.M5,
    initial_capital=1000.0
)

# 3. Definir rangos
ranges = {
    'lookback_period': [10, 15, 20, 25, 30],
    'position_size_pct': [0.2, 0.3, 0.4]
}

# 4. Ejecutar
results = optimizer.optimize(ranges, metric='sharpe_ratio')

# 5. Obtener lo mejor
best_params = optimizer.get_best_params()
```

---

## ğŸ“Š Conceptos Clave

### ParÃ¡metros Optimizables vs Fijos

#### **Optimizables** (Lo que vamos a probar)
Estos varÃ­an en cada iteraciÃ³n:
```python
param_ranges = {
    'lookback_period': [10, 15, 20, 25],  # â† VarÃ­a
    'position_size_pct': [0.2, 0.3, 0.4]  # â† VarÃ­a
}
```

#### **Fijos** (No cambian)
Estos permanecen constantes:
```python
optimizer = ParameterOptimizer(
    strategy_class=BreakoutSimple,
    market_data=df,
    symbol='BTC',              # â† Fijo (no optimiza)
    timeframe=Timeframe.M5,    # â† Fijo (no optimiza)
    initial_capital=1000.0     # â† Fijo (no optimiza)
)
```

### Â¿CuÃ¡ndo es un parÃ¡metro optimizable?

| Tipo | Ejemplo | Â¿Optimizable? | Por quÃ© |
|------|---------|---------------|---------|
| **Input estÃ¡tico** | `lookback_period=20` | âœ… **SÃ** | Directamente controlable |
| **Multiplicador** | `atr_multiplier=2.0` | âœ… **SÃ** | Escala un indicador |
| **Porcentaje** | `position_size_pct=0.3` | âœ… **SÃ** | Controla riesgo |
| **Booleano** | `use_atr_stop=True` | âœ… **SÃ** | Cambia la lÃ³gica |
| **Indicador calculado** | `stop_loss = atr * 2` | âŒ **NO** | Se calcula, no se controla |
| **MÃ©trica derivada** | `risk_reward = profit/loss` | âŒ **NO** | Resultado, no input |

**Regla de oro:** Si es un **INPUT** que la estrategia recibe en `__init__`, es optimizable.

---

## ğŸ—ï¸ Arquitectura

### Flujo de EjecuciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Cargar datos del disco (UNA SOLA VEZ)       â”‚
â”‚    df = pd.read_csv('data.csv')                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Crear ParameterOptimizer                    â”‚
â”‚    optimizer = ParameterOptimizer(            â”‚
â”‚        strategy_class=MyStrategy,             â”‚
â”‚        market_data=df  # âœ… Inyectar         â”‚
â”‚    )                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Generar Grid (todas las combinaciones)      â”‚
â”‚    5 Ã— 4 = 20 combinaciones                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Para cada combo:   â”‚
        â”‚  1. Crear estrategia con data inyectada
        â”‚  2. Ejecutar backtest (rÃ¡pido, sin I/O)
        â”‚  3. Guardar resultado
        â”‚  4. Mostrar barra de progreso
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Retornar resultados como DataFrame          â”‚
â”‚    Ordenados por mÃ©trica objetivo              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Obtener mejores parÃ¡metros                  â”‚
â”‚    Con filtro anti-fantasma (min_trades)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### InyecciÃ³n de Datos

**Â¿Por quÃ© inyectar datos?**

```
ANTES (Lento):
Combo 1: Leer disco â†’ 2 segundos
Combo 2: Leer disco â†’ 2 segundos
Combo 3: Leer disco â†’ 2 segundos
...
Total: 500 combos Ã— 2s = 16 MINUTOS âŒ

AHORA (RÃ¡pido):
Carga 1 vez: 2 segundos
Combo 1: RAM â†’ 0.01 segundos
Combo 2: RAM â†’ 0.01 segundos
Combo 3: RAM â†’ 0.01 segundos
...
Total: 2s + (500 Ã— 0.01s) = 7 SEGUNDOS âœ…

MEJORA: 200x mÃ¡s rÃ¡pido
```

---

## ğŸ“ˆ API Completa

### `ParameterOptimizer.__init__`

```python
optimizer = ParameterOptimizer(
    strategy_class=MyStrategy,      # Clase que hereda de BaseStrategy
    market_data=df,                 # DataFrame con OHLCV
    symbol='BTC',                   # ParÃ¡metro fijo
    timeframe=Timeframe.M5,         # ParÃ¡metro fijo
    initial_capital=1000.0,         # ParÃ¡metro fijo
    # ... mÃ¡s parÃ¡metros fijos
)
```

### `optimizer.optimize()`

```python
results_df = optimizer.optimize(
    param_ranges={
        'lookback_period': [10, 15, 20],
        'position_size_pct': [0.2, 0.3]
    },
    metric='sharpe_ratio',  # sharpe_ratio, roi, profit_factor, max_drawdown
    method='grid',          # Solo 'grid' en v1
    show_progress=True      # Mostrar barra de progreso
)

# Retorna: DataFrame con columnas
# [parÃ¡metros + sharpe_ratio + roi + max_drawdown + profit_factor + total_trades]
```

### `optimizer.get_best_params()`

```python
best = optimizer.get_best_params(
    metric='sharpe_ratio',  # Opcional, usa el del optimize()
    min_trades=20           # Filtro: ignorar resultados con < 20 trades
)

# Retorna: {'lookback_period': 20, 'position_size_pct': 0.3, ...}
# O None si no hay resultados vÃ¡lidos
```

### `optimizer.export_results()`

```python
optimizer.export_results('my_results.csv')
# Guarda DataFrame completo a CSV para anÃ¡lisis posterior
```

---

## ğŸ¯ Casos de Uso

### Caso 1: Optimizar Estrategia Simple

```python
# Tengo una estrategia y quiero encontrar los mejores parÃ¡metros

df = load_data('BTC', 'M5')
optimizer = ParameterOptimizer(BreakoutSimple, df, symbol='BTC', timeframe=Timeframe.M5)

results = optimizer.optimize({
    'lookback_period': range(10, 51, 5),  # 10, 15, 20, ..., 50
    'position_size_pct': [0.1, 0.2, 0.3, 0.4, 0.5]
})

best = optimizer.get_best_params(min_trades=100)
```

### Caso 2: Comparar Dos Estrategias

```python
# Ejecutar optimizador para Strategy A
optimizer_a = ParameterOptimizer(StrategyA, df, ...)
results_a = optimizer_a.optimize({...})
best_a = optimizer_a.get_best_params()

# Ejecutar optimizador para Strategy B
optimizer_b = ParameterOptimizer(StrategyB, df, ...)
results_b = optimizer_b.optimize({...})
best_b = optimizer_b.get_best_params()

# Comparar
print(f"Estrategia A Sharpe: {best_a['sharpe_ratio']}")
print(f"Estrategia B Sharpe: {best_b['sharpe_ratio']}")
```

### Caso 3: OptimizaciÃ³n por MÃºltiples MÃ©tricas

```python
# Ejecutar optimizaciÃ³n
results = optimizer.optimize({...}, metric='sharpe_ratio')

# Obtener lo mejor por diferentes mÃ©tricas
best_sharpe = optimizer.get_best_params(metric='sharpe_ratio')
best_roi = optimizer.get_best_params(metric='roi')
best_dd = optimizer.get_best_params(metric='max_drawdown', min_trades=50)
```

---

## âš¡ Performance

### Estimaciones de Tiempo

| ParÃ¡metros | Combinaciones | Tiempo |
|------------|---------------|--------|
| 2 params Ã— (5, 5) | 25 | ~30 seg |
| 2 params Ã— (10, 5) | 50 | ~60 seg |
| 3 params Ã— (5, 5, 5) | 125 | ~2 min |
| 3 params Ã— (10, 5, 5) | 250 | ~4 min |
| 4 params Ã— (5, 5, 5, 5) | 625 | ~10 min |

**Truco:** Empieza con rangos amplios, luego refina con rangos estrechos alrededor del Ã³ptimo.

---

## ğŸš¨ Trampa: Overfitting Fantasma

### El Problema

```python
# Resultado 1: lookback=100, trades=1, Sharpe=âˆ
# â†‘ Sharpe infinito porque solo 1 trade ganador (pura suerte)

# Resultado 2: lookback=20, trades=300, Sharpe=1.2
# â†‘ Sharpe real con 300 muestras (estadÃ­sticamente vÃ¡lido)
```

Sin filtro, el optimizador elegirÃ­a el Resultado 1 (engaÃ±oso).

### La SoluciÃ³n: `min_trades`

```python
# Requerer al menos 30 trades para considerar vÃ¡lido
best = optimizer.get_best_params(min_trades=30)
```

**RecomendaciÃ³n:** Usa `min_trades=20` mÃ­nimo para resultados robustos.

---

## ğŸ§ª Testing

Ejecutar tests:

```bash
pytest tests/test_optimizer.py -v
```

---

## ğŸ”® Roadmap de OptimizaciÃ³n

### Fase 4a: Grid Search (âœ… COMPLETADO - v1.0)

```python
optimizer = ParameterOptimizer(strategy, market_data)
results = optimizer.optimize({'lookback': [10, 20, 30]})
```

**CaracterÃ­sticas:**
- âœ… Grid search automÃ¡tico con `itertools.product`
- âœ… InyecciÃ³n de datos (200x mÃ¡s rÃ¡pido)
- âœ… ValidaciÃ³n inteligente de parÃ¡metros
- âœ… Filtro anti-fantasma (`min_trades`)
- âœ… Barra de progreso con `tqdm`
- âœ… Export a CSV
- âœ… Tests comprensivos

**Cuando usar:** Pocos parÃ¡metros (2-3), rangos pequeÃ±os (5-10 valores)

---

### Fase 4b: Random Search + Bayesian (â³ SIGUIENTE - v1.5)

#### Random Search
```python
# Muestreo aleatorio (mÃ¡s eficiente que grid)
results = optimizer.optimize(
    param_ranges={...},
    method='random',  # NEW
    n_iter=50  # Probar solo 50 combinaciones aleatorias
)
```

**Ventaja:** Para 100 parÃ¡metros Ã— 10 valores = 10^100 combinaciones imposibles.
Random prueba solo 50 â†’ mucho mÃ¡s rÃ¡pido.

**Cuando usar:** Espacios grandes (>5 parÃ¡metros o >100 valores totales)

---

#### Bayesian Optimization
```python
# Usa modelos probabilÃ­sticos para buscar inteligentemente
results = optimizer.optimize(
    param_ranges={...},
    method='bayesian',  # NEW
    n_calls=50,
    random_state=42
)
```

**CÃ³mo funciona:**
1. Comienza con bÃºsqueda aleatoria
2. Construye modelo probabilÃ­stico de funciÃ³n objetivo
3. Usa el modelo para predecir dÃ³nde estÃ¡ el Ã³ptimo
4. Busca alrededor de esas predicciones
5. Refina iterativamente

**Ventaja:** Converge mÃ¡s rÃ¡pido que random. ~80% mejora con 50% menos iteraciones.

**Cuando usar:** Cuando la computaciÃ³n es cara (backtests largos) y quieres mÃ¡xima eficiencia.

**Dependencia:** `pip install scikit-optimize`

---

### Fase 4c: Walk-Forward Testing (â³ FUTURO - v2.0)

```python
# ValidaciÃ³n temporal: Optimizar en pasado, probar en futuro
walk_forward = WalkForwardOptimizer(strategy, market_data, window_size='1y')

# Optimizar: 2021-2022, Probar: 2022-2023
# Optimizar: 2022-2023, Probar: 2023-2024
results = walk_forward.optimize(param_ranges, metric='sharpe_ratio')
```

**Flujo:**
```
Datos: â”œâ”€ Train1 â”€â”¤ Test1 â”€â”¤ Train2 â”€â”¤ Test2 â”€â”¤
       2021    2022    2023    2024

Iter1: Opt(2021-2022) â†’ Test(2022-2023)
Iter2: Opt(2022-2023) â†’ Test(2023-2024)
...
```

**Ventaja:** Detecta si la optimizaciÃ³n es vÃ¡lida en datos fuera de muestra.

**Cuando usar:** Validar robustez de parÃ¡metros. Evitar overfitting temporal.

---

### Fase 4d: Multiprocessing (â³ FUTURO - v2.0)

```python
# Ejecutar backtests en paralelo
results = optimizer.optimize(
    param_ranges={...},
    method='grid',
    n_jobs=4  # Usar 4 CPU cores
)
```

**Speedup:** 4 cores = 4x mÃ¡s rÃ¡pido (teÃ³ricamente)

**ImplementaciÃ³n:**
- Usar `multiprocessing.Pool`
- O `joblib.Parallel` (mÃ¡s fÃ¡cil)

**Consideraciones:**
- Overhead de procesos
- Memoria RAM (cada proceso copia datos)
- GIL en Python (threads limitados)

---

### Fase 4e: Genetic Algorithms (â³ FUTURO - v3.0)

```python
# EvoluciÃ³n de parÃ¡metros
results = optimizer.optimize(
    param_ranges={...},
    method='genetic',
    population_size=20,
    generations=50
)
```

**CÃ³mo funciona:**
1. PoblaciÃ³n inicial aleatoria
2. Selecciona mejores individuos (elitismo)
3. Crossover: combina genes de dos padres
4. MutaciÃ³n: cambia genes aleatoriamente
5. Repite N generaciones

**Ventaja:** Explora espacio de bÃºsqueda global, no solo local.

**Cuando usar:** Espacios muy complejos, multimodales.

**Dependencia:** `pip install deap`

---

## ğŸ“Š ComparaciÃ³n de MÃ©todos

| MÃ©todo | Velocidad | Calidad | ParÃ¡metros | Complejidad |
|--------|-----------|---------|-----------|-------------|
| Grid Search | â­ | â­â­â­ | 2-3 | â­ |
| Random Search | â­â­ | â­â­ | 3-5 | â­ |
| Bayesian | â­â­â­ | â­â­â­â­ | 3-10 | â­â­â­ |
| Walk-Forward | â­ | â­â­â­â­â­ | 2-3 | â­â­ |
| Genetic | â­â­ | â­â­â­â­ | 5+ | â­â­â­ |

---

## ğŸ¯ DecisiÃ³n: Â¿QuÃ© mÃ©todo elegir?

**Empezar:** Grid Search (listo hoy)
â†“
**DespuÃ©s:** Random Search (semana 1)
â†“
**MÃ¡s tarde:** Bayesian si backtests son lentos
â†“
**Robusto:** Walk-Forward para validar
â†“
**Avanzado:** Genetic para espacios complejos

---

## ğŸ“š Ejemplos Completos

- **OptimizaciÃ³n bÃ¡sica:** `notebooks/prueba_optimizer.ipynb`
- **VisualizaciÃ³n 3D:** `notebooks/prueba_optimizer_visualization.ipynb`

---

## ğŸ¨ VisualizaciÃ³n 3D de Resultados

### OptimizationPlotter

El mÃ³dulo `optimization.visualizer` proporciona visualizaciÃ³n 3D del espacio de parÃ¡metros.

```python
from optimization import OptimizationPlotter

# DespuÃ©s de ejecutar la optimizaciÃ³n
plotter = OptimizationPlotter(results_df)

# Superficie 3D con mapa de color rojo â†’ azul
plotter.plot_3d_surface(
    x_param='lookback_period',
    y_param='position_size_pct',
    metric='sharpe_ratio',
    figsize=(14, 10)
)
```

### CaracterÃ­sticas

- **Superficie 3D estilo MATLAB**: Malla tridimensional con proyecciÃ³n en el suelo
- **Colormap rojo â†’ azul**: Rojo = valores bajos (malos), Azul = valores altos (buenos)
- **MÃ©tricas soportadas**: `sharpe_ratio`, `roi`, `max_drawdown`, `profit_factor`, `total_trades`
- **Interactividad**: RotaciÃ³n 3D para explorar desde diferentes Ã¡ngulos

### ParÃ¡metros

```python
def plot_3d_surface(
    x_param: str,           # ParÃ¡metro para eje X
    y_param: str,           # ParÃ¡metro para eje Y
    metric: str,            # MÃ©trica para eje Z
    fill_value: float = 0.0,  # Valor para rellenar huecos
    figsize: tuple = (14, 10)  # TamaÃ±o de la figura
)
```

### InterpretaciÃ³n

**Superficies Planas:**
- âœ… ParÃ¡metro robusto (insensible a variaciones)
- Ejemplo: Si cambiar `lookback` de 10 a 30 no afecta el Sharpe â†’ robusto

**Superficies con Picos:**
- âš ï¸ ParÃ¡metro sensible (requiere ajuste fino)
- Ejemplo: Si solo `lookback=20` da buen Sharpe â†’ sensible, overfitting probable

**Zonas Azules (Altas):**
- âœ… Regiones Ã³ptimas para operar
- Busca "mesetas azules" amplias (robustas) vs "picos azules" estrechos (frÃ¡giles)

---

## â“ FAQ

**P: Â¿Puedo optimizar indicadores tÃ©cnicos?**
R: No directamente. Optimiza los parÃ¡metros que **controlan** los indicadores (perÃ­odos, multiplicadores, etc.).

**P: Â¿QuÃ© pasa si tengo 100 parÃ¡metros?**
R: No hagas eso. Limita a 2-3 mÃ¡ximo. Grid Search crece exponencialmente.

**P: Â¿Es Grid Search lo mejor?**
R: Para v1 es simple y funciona. Random Search y Bayesian son mÃ¡s eficientes para espacios grandes.

**P: Â¿CÃ³mo evito overfitting?**
R: Usa `min_trades`, haz walk-forward testing, valida en datos fuera de muestra.

**P: Â¿Puedo optimizar stops dinÃ¡micos?**
R: SÃ­, optimiza el **multiplicador** (ej: `atr_multiplier`), no el stop directo.

---

## ğŸ“ Soporte

Para reportar bugs o sugerencias: `issues` en el repositorio.

---

**Â¡Happy optimizing! ğŸš€**
